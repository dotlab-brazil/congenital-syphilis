{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experts - BODDS Experiment\n",
        "\n",
        "Balanced data set and one-hot encoding with the column related to not informed by the patient removed from the data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "print('ENV variables loaded successfully!')\n",
        "\n",
        "module_path = os.path.abspath(os.path.join('../../..'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from lib.env_var_keys import EnvVarKeys\n",
        "\n",
        "pre_processed_dataset_path = os.getenv(EnvVarKeys.PRE_PROCESSED_DATASET_PATH_KEY.value)\n",
        "df = pd.read_csv(pre_processed_dataset_path, sep=',', low_memory=False)\n",
        "\n",
        "print(f'Pre-processed dataset shape: {df.shape}')\n",
        "\n",
        "RANDOM_STATE = 28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lib.dataframe_helper import vdrl_count\n",
        "\n",
        "vdrl_count(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lib.dataframe_helper import vdrl_count\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "from lib.dataframe_helper import fill_nan, vdrl_count\n",
        "\n",
        "df = df.drop(columns=['empty_count', 'empty_columns'], axis=1)\n",
        "print(f'Shape: {df.shape}')\n",
        "\n",
        "vdrl_count(df)\n",
        "\n",
        "df = fill_nan(df)\n",
        "\n",
        "columns_to_one_hot_encoding = [\n",
        "  'HAS_PREG_RISK',\n",
        "  'NUM_ABORTIONS',\n",
        "  'PLAN_PREGNANCY',\n",
        "  'MARITAL_STATUS',\n",
        "  'FOOD_INSECURITY',\n",
        "  'NUM_LIV_CHILDREN',\n",
        "  'NUM_PREGNANCIES',\n",
        "  'FAM_PLANNING',\n",
        "  'LEVEL_SCHOOLING',\n",
        "  'FAM_INCOME',\n",
        "]\n",
        "df = pd.get_dummies(df, columns=columns_to_one_hot_encoding)\n",
        "print(f'\\nShape after one-hot encoding: {df.shape}')\n",
        "\n",
        "columns_to_drop = [\n",
        "  'HAS_PREG_RISK_2.0',\n",
        "  'NUM_ABORTIONS_3.0',\n",
        "  'PLAN_PREGNANCY_2.0',\n",
        "  'MARITAL_STATUS_5.0',\n",
        "  'FOOD_INSECURITY_2.0',\n",
        "  'NUM_LIV_CHILDREN_4.0',\n",
        "  'NUM_PREGNANCIES_4.0',\n",
        "  'FAM_PLANNING_2.0',\n",
        "  'LEVEL_SCHOOLING_9.0',\n",
        "  'FAM_INCOME_3.0'\n",
        "]\n",
        "\n",
        "df = df.drop(columns=columns_to_drop, axis=1)\n",
        "print(f'\\nShape after drop dummy columns: {df.shape}')\n",
        "\n",
        "# Create X and y\n",
        "X = np.array(df.drop('mc_cri_vdrl', axis=1))\n",
        "y = np.array(df['mc_cri_vdrl'])\n",
        "\n",
        "undersampler = RandomUnderSampler(sampling_strategy='not minority', random_state=RANDOM_STATE)\n",
        "X, y = undersampler.fit_resample(X, y)\n",
        "\n",
        "print(f'\\nShape after undersampling: ({X.shape[0]}, {X.shape[1] + 1})')\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
        "\n",
        "train_unique, train_counts = np.unique(y_train, return_counts=True)\n",
        "test_unique, test_counts = np.unique(y_test, return_counts=True)\n",
        "print(f'Shape after splitting: train={X_train.shape} [0 = {train_counts[0]}, 1 = {train_counts[1]}] | test={X_test.shape} [0 = {test_counts[0]}, 1 = {test_counts[1]}]')\n",
        "\n",
        "feature_names = df.drop('mc_cri_vdrl', axis=1).columns.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lib.classifier_helper import ClassifierHelper\n",
        "\n",
        "clf_helper = ClassifierHelper(X_train, X_test, y_train, y_test, feature_names, False)\n",
        "\n",
        "clf_helper.exec_random_forest()\n",
        "clf_helper.exec_knn()\n",
        "clf_helper.exec_decision_tree()\n",
        "clf_helper.exec_ada_boost()\n",
        "clf_helper.exec_gradient_boosting()\n",
        "clf_helper.exec_svm()\n",
        "clf_helper.exec_logistic_regression()\n",
        "clf_helper.exec_xgboost()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

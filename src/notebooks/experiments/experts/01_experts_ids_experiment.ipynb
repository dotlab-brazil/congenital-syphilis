{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experts - IDS Experiment\n",
        "\n",
        "Imbalanced data set with 2,327 records (826 positive cases and 1,501 negative cases) and 26 attributes. As the original data set contained numerous negative cases when compared to the number of positive cases (40,936 negative cases and 826 positive cases), we used the random undersampling technique to reduce the difference between the positive and negative congenital syphilis cases, setting a ratio of 55% of the number of samples in the minority class (positive cases) over the number of samples in the majority class (negative cases) after resampling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "print('ENV variables loaded successfully!')\n",
        "\n",
        "module_path = os.path.abspath(os.path.join('../../..'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from lib.env_var_keys import EnvVarKeys\n",
        "\n",
        "pre_processed_dataset_path = os.getenv(EnvVarKeys.PRE_PROCESSED_DATASET_PATH_KEY.value)\n",
        "df = pd.read_csv(pre_processed_dataset_path, sep=',', low_memory=False)\n",
        "\n",
        "print(f'Pre-processed dataset shape: {df.shape}')\n",
        "\n",
        "RANDOM_STATE = 28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lib.dataframe_helper import vdrl_count\n",
        "\n",
        "vdrl_count(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "from lib.dataframe_helper import fill_nan\n",
        "\n",
        "print(f'Shape before: {df.shape}')\n",
        "\n",
        "df = fill_nan(df)\n",
        "\n",
        "expert_attributes = [\n",
        "  'VDRL_RESULT',\n",
        "  'HAS_PREG_RISK',\n",
        "  'NUM_ABORTIONS',\n",
        "  'PLAN_PREGNANCY',\n",
        "  'MARITAL_STATUS',\n",
        "  'FOOD_INSECURITY',\n",
        "  'NUM_LIV_CHILDREN',\n",
        "  'NUM_PREGNANCIES',\n",
        "  'FAM_PLANNING',\n",
        "  'LEVEL_SCHOOLING',\n",
        "  'FAM_INCOME',\n",
        "  'AGE',\n",
        "]\n",
        "\n",
        "df = df[expert_attributes]\n",
        "\n",
        "print(f'Shape after: {df.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Create X and y\n",
        "X = np.array(df.drop('VDRL_RESULT', axis=1))\n",
        "y = np.array(df['VDRL_RESULT'])\n",
        "\n",
        "undersampler = RandomUnderSampler(sampling_strategy=0.55, random_state=RANDOM_STATE)\n",
        "X, y = undersampler.fit_resample(X, y)\n",
        "\n",
        "print(f'\\nShape after undersampling: ({X.shape[0]}, {X.shape[1] + 1})')\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
        "\n",
        "train_unique, train_counts = np.unique(y_train, return_counts=True)\n",
        "test_unique, test_counts = np.unique(y_test, return_counts=True)\n",
        "print(f'Shape after splitting: train={X_train.shape} [0 = {train_counts[0]}, 1 = {train_counts[1]}] | test={X_test.shape} [0 = {test_counts[0]}, 1 = {test_counts[1]}]')\n",
        "\n",
        "feature_names = df.drop('VDRL_RESULT', axis=1).columns.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lib.classifier_helper import ClassifierHelper\n",
        "\n",
        "clf_helper = ClassifierHelper(X_train, X_test, y_train, y_test, feature_names, False)\n",
        "\n",
        "clf_helper.exec_random_forest()\n",
        "clf_helper.exec_knn()\n",
        "clf_helper.exec_decision_tree()\n",
        "clf_helper.exec_ada_boost()\n",
        "clf_helper.exec_gradient_boosting()\n",
        "clf_helper.exec_svm()\n",
        "clf_helper.exec_logistic_regression()\n",
        "clf_helper.exec_xgboost()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.13 ('syphilis-env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "416ab2233af069778f21dca19dabf29eb63b81be59c1f4646b2eca8f372fbc65"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

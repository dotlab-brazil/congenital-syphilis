{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading env variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "print('ENV variables loaded successfully!')\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading pre-processed database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lib.env_var_keys import EnvVarKeys\n",
    "from lib.dataframe_helper import fill_nan\n",
    "\n",
    "# Get the database file path\n",
    "pre_processed_dataset_path = os.getenv(EnvVarKeys.PRE_PROCESSED_DATASET_PATH_KEY.value)\n",
    "df = pd.read_csv(pre_processed_dataset_path, sep=',', low_memory=False)\n",
    "df = df.drop(columns=['empty_count', 'empty_columns'], axis=1)\n",
    "df = fill_nan(df)\n",
    "\n",
    "print(f'Pre-processed data set shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution(df, target_col, numeric_columns=[]):\n",
    "  '''\n",
    "  Get DataFrame distribution for a given target column.\n",
    "  \n",
    "  Parameters\n",
    "  ----------\n",
    "  df : pandas.DataFrame\n",
    "    DataFrame to get distribution from.\n",
    "  target_col : str\n",
    "    Target column name.\n",
    "  numeric_columns : list\n",
    "    List of numeric columns to get distribution from.\n",
    "    \n",
    "  Returns\n",
    "  -------\n",
    "  pandas.DataFrame\n",
    "    DataFrame with distribution for the given target column.\n",
    "  '''\n",
    "  \n",
    "  total = df.shape[0]\n",
    "  columns = df.loc[:, df.columns != target_col].columns.to_list()\n",
    "  \n",
    "  dfs_by_target_col_classes = {}\n",
    "  values_target_col = df[target_col].value_counts().index.to_list()\n",
    "  \n",
    "  for value in values_target_col:\n",
    "    dfs_by_target_col_classes[value] = df[df[target_col] == value]\n",
    "  \n",
    "  data = {'Attributes': [], 'Total': []}\n",
    "  \n",
    "  for value_target_col in values_target_col:\n",
    "    data[f'{target_col}:{value_target_col}'] = []\n",
    "  \n",
    "  for col in columns:\n",
    "    if (col in numeric_columns):\n",
    "      mean = df[col].mean()\n",
    "      std = df[col].std()\n",
    "      data['Attributes'].append(col)\n",
    "      data['Total'].append(f'{mean:.1f} ({std:.1f})')\n",
    "      \n",
    "      for df_by_target_col_key in dfs_by_target_col_classes.keys():\n",
    "          mean_by_target_col = dfs_by_target_col_classes[df_by_target_col_key][col].mean()\n",
    "          std_by_target_col = dfs_by_target_col_classes[df_by_target_col_key][col].std()\n",
    "          \n",
    "          data[f'{target_col}:{df_by_target_col_key}'].append(f'{mean_by_target_col:.1f} ({std_by_target_col:.1f})')\n",
    "    else: \n",
    "      value_counts_total = df[col].value_counts()\n",
    "      value_index = value_counts_total.index.to_list()\n",
    "      value_index.sort()\n",
    "      \n",
    "      for index in value_index:\n",
    "        data['Attributes'].append(f'{col}:{index}')\n",
    "        data['Total'].append(f'{value_counts_total[index]}/{total} ({(value_counts_total[index]/total) * 100:.1f})')\n",
    "        \n",
    "        for df_by_target_col_key in dfs_by_target_col_classes.keys():\n",
    "          total_by_target_col_class = dfs_by_target_col_classes[df_by_target_col_key].shape[0]\n",
    "          value_counts_total_by_target_col = dfs_by_target_col_classes[df_by_target_col_key][col].value_counts()\n",
    "          \n",
    "          if index in value_counts_total_by_target_col.index.to_list():\n",
    "            data[f'{target_col}:{df_by_target_col_key}'].append(f'{value_counts_total_by_target_col[index]}/{total_by_target_col_class} ({(value_counts_total_by_target_col[index]/total_by_target_col_class)  * 100:.1f})')\n",
    "          else:\n",
    "            data[f'{target_col}:{df_by_target_col_key}'].append('-')\n",
    "            \n",
    "  return pd.DataFrame(data)\n",
    "  \n",
    "\n",
    "df_distribution = get_distribution(df, 'mc_cri_vdrl', ['idade'])\n",
    "\n",
    "df_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.getenv(EnvVarKeys.DISTRIBUTION_DATASET_PATH_KEY.value)\n",
    "df_distribution.to_csv(dataset_path, sep=',',  index=False)\n",
    "\n",
    "print(f'Distribution data set saved to: {dataset_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('syphilis-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "416ab2233af069778f21dca19dabf29eb63b81be59c1f4646b2eca8f372fbc65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
